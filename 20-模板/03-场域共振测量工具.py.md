## 1）整体概要

该代码段旨在为“上下文工程”（Context Engineering）领域中的“神经网络场”（Neural Field）提供一套全面的分析和度量工具。其核心目标是量化评估神经网络场的属性，如共振（Resonance）、一致性（Coherence）、稳定性（Stability）以及信息熵（Entropy），从而为神经网络场的优化、调谐和演化提供指导。

具体来说，这个模块允许用户：

* **量化模式间的语义相似性**：通过多种算法（如余弦相似度、词语重叠、词嵌入）计算文本模式之间的共振得分。

* **评估场（Field）的整体一致性**：衡量场中各个模式与吸引子之间的对齐程度和组织结构。

* **评估场（Field）的持久性和秩序**：分析场的稳定性，判断其抵御扰动的能力。

* **获取全面的场指标**：提供一个整合的接口，计算并汇总场的多种关键量化指标。

* **可视化场的状态**：生成不同格式（ASCII、文本、JSON）的场状态摘要，帮助直观理解。

* **深入分析与推荐**：基于量化指标对场的结构、演化潜力进行深入分析，并提出改进建议。

## 2）模块说明

以下是代码中定义的各个类及其作用：

* **`logging` 配置**

  * **作用**：设置日志记录器，用于输出模块内部的运行信息、警告和错误，便于调试和监控。

* **`ResonanceMeasurer`**

  * **作用**：专门用于计算两个文本模式（`pattern`）之间的“共振”得分，即它们之间的语义相似性。

  * **初始化参数**：

    * `method`: 共振计算方法，支持 `"cosine"`（余弦相似度，基于词频）、`"overlap"`（词语重叠，基于Jaccard相似度）和 `"embedding"`（词嵌入相似度，需要 `sentence-transformers` 库）。

    * `threshold`: 共振得分低于此阈值时将被视为 0，用于过滤弱共振。

    * `amplification`: 对共振得分进行放大，增强显著共振的效果。

  * **核心方法**：

    * `measure(pattern1: str, pattern2: str)`: 根据选定方法计算两个模式的共振得分。

    * `_cosine_similarity`, `_word_overlap`, `_embedding_similarity`: 内部方法，实现具体的共振计算逻辑。

    * `_get_word_freq`: 辅助方法，用于计算词频。

    * `_initialize_embedding_model`: 懒加载并初始化词嵌入模型。

* **`CoherenceMeasurer`**

  * **作用**：评估神经网络场（`field`）的整体“一致性”或内在连贯性。

  * **初始化参数**：

    * `method`: 一致性计算方法，支持 `"pairwise"`（两两模式共振平均）、`"attractor_alignment"`（模式与吸引子的对齐程度）和 `"entropy"`（基于熵的简化一致性）。

    * `sampling`: 对于大型场，采样的策略（`"full"`、`"random"`、`"strength_weighted"`）。

    * `sample_size`: 采样时考虑的模式数量。

  * **核心方法**：

    * `measure(field: Any)`: 计算场的一致性得分。

    * `_pairwise_coherence`, `_attractor_alignment`, `_entropy_coherence`: 内部方法，实现不同的一致性计算逻辑。

    * `_sample_patterns`, `_get_attractors`: 辅助方法，用于从 `field` 对象中提取模式和吸引子。

  * **依赖**：内部实例化并使用了 `ResonanceMeasurer` 来进行模式间的共振计算。



* **`StabilityMeasurer`**

  * **作用**：评估神经网络场（`field`）的“稳定性”，即其维持特定状态和抵抗扰动的能力。

  * **初始化参数**：

    * `attractor_weight`: 吸引子强度在稳定性计算中的权重。

    * `organization_weight`: 模式组织度（通过一致性衡量）在稳定性计算中的权重。

  * **核心方法**：

    * `measure(field: Any)`: 计算场的稳定性得分。

  * **依赖**：内部实例化并使用了 `CoherenceMeasurer` 来计算模式组织度。



* **`FieldResonanceMeasurer`**

  * **作用**：这是一个综合性的工具，整合了 `ResonanceMeasurer`、`CoherenceMeasurer` 和 `StabilityMeasurer`，提供一套完整的神经网络场属性度量功能。它是模块的主要对外接口。

  * **初始化参数**：

    * `config_path`: 可选参数，指定一个 YAML 配置文件路径来加载自定义配置，否则使用默认配置。

  * **核心方法**：

    * `measure_resonance(pattern1: str, pattern2: str)`: 委托给内部的 `ResonanceMeasurer`。

    * `measure_coherence(field: Any)`: 委托给内部的 `CoherenceMeasurer`。

    * `measure_stability(field: Any)`: 委托给内部的 `StabilityMeasurer`。

    * `get_field_metrics(field: Any)`: 计算并返回一个包含场的一致性、稳定性、吸引子/模式数量、平均强度、熵等全面指标的字典。

    * `visualize_field(field: Any, format: str = "ascii")`: 生成场的文本可视化（支持 ASCII 图、纯文本、JSON 格式），以便直观理解。

  * **内部辅助方法**：包括配置加载、提取吸引子和模式、计算熵以及不同格式的可视化生成方法。



* **`FieldAnalyzer`**

  * **作用**：在 `FieldResonanceMeasurer` 提供的量化指标基础上，进行更深层次的场分析，并提供洞察和改进建议。

  * **初始化参数**：

    * `measurer`: 可选参数，可以传入一个已初始化的 `FieldResonanceMeasurer` 实例，否则会自动创建一个新的。

  * **核心方法**：

    * `analyze_field(field: Any)`: 执行对场的全面分析，返回包含指标、吸引子分析、模式分析、演化潜力分析以及建议的字典。

  * **内部辅助方法**：

    * `_analyze_attractors`: 分析吸引子的数量、强度分布、多样性和主导主题。

    * `_analyze_patterns`: 分析模式的数量、组织度、与吸引子的对齐程度和碎片化。

    * `_analyze_evolution_potential`: 分析场的演化潜力，判断其是否过于僵化、混乱或处于最佳状态，并推荐相应的操作。

    * `_generate_recommendations`: 根据各项分析结果，生成具体的场改进建议。



## 3）代码的运行示例

以下示例演示了如何使用 `FieldResonanceMeasurer` 和 `FieldAnalyzer` 来评估和分析一个模拟的“神经网络场”。

```python
import math
import time
import logging
from typing import Dict, List, Any, Optional, Callable, Union, Tuple, Set
from collections import defaultdict
import yaml
import json

# 配置日志（这部分在原代码的顶部，这里为了示例完整性再次包含）
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("field_resonance")

# --- 粘贴上面提供的所有类定义在这里 ---
# (ResonanceMeasurer, CoherenceMeasurer, StabilityMeasurer, FieldResonanceMeasurer, FieldAnalyzer)

# ------------------------------------------------------------------------------
# Usage Examples (与原代码提供的完全一致，只为展示运行效果)
# ------------------------------------------------------------------------------

def measure_field_resonance_example():
    """Example usage of field resonance measurement."""
    # 创建一个简单的模拟场（MockField）用于演示
    # 真实场景中，field 会是一个更复杂的对象，它能提供 patterns 和 attractors
    class MockField:
        def __init__(self):
            # field.state 模拟场中活跃的模式及其强度
            self.state = {
                "Neural fields treat context as a continuous medium.": 0.9,
                "Information persists through resonance rather than explicit storage.": 0.8,
                "Patterns that align with existing field structures decay more slowly.": 0.7,
                "Field boundaries determine how information flows in and out.": 0.6,
                "New inputs interact with the entire field, not just recent tokens.": 0.5
            }
            # field.attractors 模拟场中的吸引子及其模式和强度
            self.attractors = {
                "attractor1": {
                    "pattern": "Neural fields represent context as a continuous semantic landscape.",
                    "strength": 0.9
                },
                "attractor2": {
                    "pattern": "Resonance is a key mechanism for information persistence.",
                    "strength": 0.8
                }
            }
        
        # 为了兼容 CoherenceMeasurer 和 FieldResonanceMeasurer 中的 _get_patterns 和 _get_attractors 方法
        # 即使它们有 try-except 处理 AttributeError，显式提供这些方法会让逻辑更清晰
        def get_patterns(self) -> List[Tuple[str, float]]:
            return [(pattern, strength) for pattern, strength in self.state.items()]
            
        def get_attractors(self) -> List[Tuple[str, float]]:
            return [(attractor['pattern'], attractor['strength']) 
                    for attractor in self.attractors.values()]

    print("--- 启动神经网络场共振测量示例 ---")
    
    # 创建一个场实例
    field = MockField()
    
    # 创建一个测量器实例
    measurer = FieldResonanceMeasurer()
    
    # 测量两个模式之间的共振
    pattern1 = "Neural fields enable persistent context."
    pattern2 = "Information persists in neural fields through resonance."
    resonance = measurer.measure_resonance(pattern1, pattern2)
    print(f"\n1. 模式间共振: '{pattern1}' 与 '{pattern2}' 之间的共振得分: {resonance:.2f}")
    
    # 测量场的整体一致性
    coherence = measurer.measure_coherence(field)
    print(f"\n2. 场一致性: 场的整体一致性得分: {coherence:.2f}")
    
    # 测量场的稳定性
    stability = measurer.measure_stability(field)
    print(f"\n3. 场稳定性: 场的稳定性得分: {stability:.2f}")
    
    # 获取场的综合指标
    metrics = measurer.get_field_metrics(field)
    print("\n4. 场的综合指标:")
    for key, value in metrics.items():
        # 对于非浮点数指标（如计数），直接打印整数
        if 'count' in key:
            print(f"- {key}: {int(value)}")
        else:
            print(f"- {key}: {value:.2f}")
    
    # 可视化场的状态 (ASCII 格式)
    visualization = measurer.visualize_field(field, format="ascii")
    print("\n5. 场状态可视化 (ASCII):")
    print(visualization)

    # 可视化场的状态 (Text 格式)
    visualization_text = measurer.visualize_field(field, format="text")
    print("\n6. 场状态可视化 (Text):")
    print(visualization_text)

    # 可视化场的状态 (JSON 格式)
    visualization_json = measurer.visualize_field(field, format="json")
    print("\n7. 场状态可视化 (JSON):")
    print(visualization_json)
    
    # 分析场并获取建议
    analyzer = FieldAnalyzer(measurer) # 可以传入已有的 measurer
    analysis = analyzer.analyze_field(field)
    
    print("\n8. 场分析结果:")
    print(f"   演化潜力: {analysis['evolution_analysis']['evolution_potential']}")
    print("   改进建议:")
    for recommendation in analysis['recommendations']:
        print(f"   - {recommendation}")

if __name__ == "__main__":
    # 执行示例
    measure_field_resonance_example()
```



**运行结果示例 (部分输出)：**



由于输出内容较多，这里仅展示部分关键结果。实际运行时会输出完整的各项指标、可视化图和分析建议。



```plain&#x20;text
--- 启动神经网络场共振测量示例 ---

1. 模式间共振: 'Neural fields enable persistent context.' 与 'Information persists in neural fields through resonance.' 之间的共振得分: 0.24

2. 场一致性: 场的整体一致性得分: 0.85

3. 场稳定性: 场的稳定性得分: 0.86

4. 场的综合指标:
- coherence: 0.85
- stability: 0.86
- attractor_count: 2
- avg_attractor_strength: 0.85
- max_attractor_strength: 0.90
- pattern_count: 5
- avg_pattern_strength: 0.70
- entropy: 0.93
- information_density: 64.60

5. 场状态可视化 (ASCII):
================================================================================
NEURAL FIELD VISUALIZATION
================================================================================
FIELD METRICS:
Coherence:    *****************    0.85
Stability:     *****************    0.86
Entropy:       ******************   0.93
Attractors:    2
Patterns:      5
--------------------------------------------------------------------------------
ATTRACTORS:
A1 (0.90): ##################   Neural fields represent context as a continuous ...
A2 (0.80): ################   Resonance is a key mechanism for information per...
--------------------------------------------------------------------------------
ACTIVE PATTERNS:
P1 (0.90): ******************   Neural fields treat context as a continuous medium.
P2 (0.80): ****************   Information persists through resonance rather than explicit storage.
P3 (0.70): **************   Patterns that align with existing field structures decay more slowly.
P4 (0.60): ************   Field boundaries determine how information flows in and out.
P5 (0.50): **********   New inputs interact with the entire field, not just recent tokens.
--------------------------------------------------------------------------------
RESONANCE MAP:
P1 ↔ A1: -----------------    0.86
P1 ↔ A2: -----              0.26
P2 ↔ A1: -----              0.24
P2 ↔ A2: --------------     0.73
--------------------------------------------------------------------------------

... (Text and JSON visualizations will follow) ...

8. 场分析结果:
   演化潜力: optimal
   改进建议:
   - Maintain current field state with periodic reinforcement
```



**说明：**



* **MockField**：为了模拟真实的“神经网络场”，我们定义了一个 `MockField` 类。它包含 `state`（表示场中活跃的模式及其强度）和 `attractors`（表示场的吸引子及其模式和强度）。在实际应用中，`FieldResonanceMeasurer` 及其组件会与一个更复杂的、实际的神经网络场数据结构进行交互。

* **依赖与回退**：`ResonanceMeasurer` 在使用 `"embedding"` 方法时，如果缺少 `sentence-transformers` 库，它会发出警告并回退到 `cosine` 相似度计算。

* **多维度评估**：示例展示了如何计算单个模式间的共振、场的整体一致性、场的稳定性，以及获取包含多种统计信息的综合指标。

* **可视化与分析**：模块不仅提供量化数据，还能生成ASCII图、纯文本和JSON格式的场可视化报告，并通过 `FieldAnalyzer` 提供高级分析和针对性的改进建议。



```python
"""
Field Resonance Measurement Tool
--------------------------------

This module provides tools for measuring resonance, coherence, and other properties
of neural fields in context engineering applications. It enables quantitative
assessment of field states to guide optimization and tuning.

Usage:
    # Initialize a resonance measurer
    measurer = FieldResonanceMeasurer()
    
    # Measure resonance between patterns
    score = measurer.measure_resonance(pattern1, pattern2)
    
    # Measure field coherence
    coherence = measurer.measure_coherence(field)
    
    # Get comprehensive field metrics
    metrics = measurer.get_field_metrics(field)
"""

import math
import time
import logging
from typing import Dict, List, Any, Optional, Callable, Union, Tuple, Set
from collections import defaultdict
import yaml
import json

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("field_resonance")

# ------------------------------------------------------------------------------
# Resonance Measurement
# ------------------------------------------------------------------------------

class ResonanceMeasurer:
    """Measures resonance between patterns in a neural field."""
    
    def __init__(self, method: str = "cosine", threshold: float = 0.2, amplification: float = 1.2):
        """
        Initialize the resonance measurer.
        
        Args:
            method: Resonance calculation method ("cosine", "overlap", "embedding")
            threshold: Minimum threshold for resonance effects
            amplification: Amplification factor for resonance effects
        """
        self.method = method
        self.threshold = threshold
        self.amplification = amplification
        
        # Initialize embedding model if needed
        self.embedding_model = None
        if method == "embedding":
            try:
                self._initialize_embedding_model()
            except ImportError:
                logger.warning("Embedding model not available, falling back to cosine similarity")
                self.method = "cosine"
    
    def _initialize_embedding_model(self):
        """Initialize the embedding model for semantic similarity."""
        try:
            import numpy as np
            from sentence_transformers import SentenceTransformer
            self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
            self.np = np
        except ImportError:
            raise ImportError("Sentence-transformers not installed. Install with 'pip install sentence-transformers'")
    
    def measure(self, pattern1: str, pattern2: str) -> float:
        """
        Measure resonance between two patterns.
        
        Args:
            pattern1: First pattern
            pattern2: Second pattern
            
        Returns:
            Resonance score (0.0 to 1.0)
        """
        if not pattern1 or not pattern2:
            return 0.0
            
        if self.method == "cosine":
            return self._cosine_similarity(pattern1, pattern2)
        elif self.method == "overlap":
            return self._word_overlap(pattern1, pattern2)
        elif self.method == "embedding":
            return self._embedding_similarity(pattern1, pattern2)
        else:
            logger.warning(f"Unknown resonance method: {self.method}, falling back to cosine")
            return self._cosine_similarity(pattern1, pattern2)
    
    def _cosine_similarity(self, pattern1: str, pattern2: str) -> float:
        """Calculate cosine similarity based on word frequency."""
        # Get word frequency dictionaries
        words1 = self._get_word_freq(pattern1)
        words2 = self._get_word_freq(pattern2)
        
        # Find common words
        common_words = set(words1.keys()) & set(words2.keys())
        
        # Calculate dot product
        dot_product = sum(words1[word] * words2[word] for word in common_words)
        
        # Calculate magnitudes
        mag1 = math.sqrt(sum(value ** 2 for value in words1.values()))
        mag2 = math.sqrt(sum(value ** 2 for value in words2.values()))
        
        # Avoid division by zero
        if mag1 == 0 or mag2 == 0:
            return 0.0
            
        # Calculate cosine similarity
        similarity = dot_product / (mag1 * mag2)
        
        # Apply amplification and threshold
        if similarity < self.threshold:
            return 0.0
            
        return min(1.0, similarity * self.amplification)
    
    def _word_overlap(self, pattern1: str, pattern2: str) -> float:
        """Calculate similarity based on word overlap."""
        # Get word sets
        words1 = set(pattern1.lower().split())
        words2 = set(pattern2.lower().split())
        
        # Calculate overlap
        if not words1 or not words2:
            return 0.0
            
        overlap = len(words1 & words2)
        union = len(words1 | words2)
        
        # Calculate Jaccard similarity
        similarity = overlap / union
        
        # Apply amplification and threshold
        if similarity < self.threshold:
            return 0.0
            
        return min(1.0, similarity * self.amplification)
    
    def _embedding_similarity(self, pattern1: str, pattern2: str) -> float:
        """Calculate similarity based on embedding vectors."""
        if self.embedding_model is None:
            logger.warning("Embedding model not initialized, falling back to cosine similarity")
            return self._cosine_similarity(pattern1, pattern2)
            
        # Get embeddings
        embedding1 = self.embedding_model.encode([pattern1])[0]
        embedding2 = self.embedding_model.encode([pattern2])[0]
        
        # Calculate cosine similarity
        similarity = self.np.dot(embedding1, embedding2) / (
            self.np.linalg.norm(embedding1) * self.np.linalg.norm(embedding2)
        )
        
        # Apply amplification and threshold
        if similarity < self.threshold:
            return 0.0
            
        return min(1.0, float(similarity * self.amplification))
    
    def _get_word_freq(self, text: str) -> Dict[str, int]:
        """Get word frequency dictionary from text."""
        words = text.lower().split()
        freq = defaultdict(int)
        for word in words:
            freq[word] += 1
        return freq

# ------------------------------------------------------------------------------
# Coherence Measurement
# ------------------------------------------------------------------------------

class CoherenceMeasurer:
    """Measures coherence of a neural field."""
    
    def __init__(self, method: str = "attractor_alignment", sampling: str = "strength_weighted", sample_size: int = 100):
        """
        Initialize the coherence measurer.
        
        Args:
            method: Coherence calculation method ("pairwise", "attractor_alignment", "entropy")
            sampling: Sampling strategy for large fields ("full", "random", "strength_weighted")
            sample_size: Sample size for large fields
        """
        self.method = method
        self.sampling = sampling
        self.sample_size = sample_size
        self.resonance_measurer = ResonanceMeasurer()
    
    def measure(self, field: Any) -> float:
        """
        Measure coherence of a field.
        
        Args:
            field: Neural field to measure
            
        Returns:
            Coherence score (0.0 to 1.0)
        """
        if self.method == "pairwise":
            return self._pairwise_coherence(field)
        elif self.method == "attractor_alignment":
            return self._attractor_alignment(field)
        elif self.method == "entropy":
            return self._entropy_coherence(field)
        else:
            logger.warning(f"Unknown coherence method: {self.method}, falling back to attractor_alignment")
            return self._attractor_alignment(field)
    
    def _pairwise_coherence(self, field: Any) -> float:
        """Calculate coherence based on pairwise pattern resonance."""
        # Get patterns to evaluate
        patterns = self._sample_patterns(field)
        
        if len(patterns) < 2:
            return 1.0  # Perfect coherence for a single pattern
            
        # Calculate all pairwise resonances
        total_resonance = 0.0
        pair_count = 0
        
        for i, (pattern1, strength1) in enumerate(patterns):
            for j, (pattern2, strength2) in enumerate(patterns):
                if i < j:  # Only compare each pair once
                    resonance = self.resonance_measurer.measure(pattern1, pattern2)
                    weighted_resonance = resonance * strength1 * strength2
                    total_resonance += weighted_resonance
                    pair_count += 1
        
        if pair_count == 0:
            return 0.0
            
        # Calculate average resonance
        avg_resonance = total_resonance / pair_count
        
        return avg_resonance
    
    def _attractor_alignment(self, field: Any) -> float:
        """Calculate coherence based on alignment with attractors."""
        # Get attractors and patterns
        attractors = self._get_attractors(field)
        patterns = self._sample_patterns(field)
        
        if not attractors:
            return self._pairwise_coherence(field)  # Fall back to pairwise if no attractors
            
        # Calculate alignment with attractors
        total_alignment = 0.0
        total_weight = 0.0
        
        for pattern, pattern_strength in patterns:
            # Calculate alignment with each attractor
            best_alignment = 0.0
            for attractor, attractor_strength in attractors:
                alignment = self.resonance_measurer.measure(pattern, attractor)
                if alignment > best_alignment:
                    best_alignment = alignment
            
            # Weight by pattern strength
            total_alignment += best_alignment * pattern_strength
            total_weight += pattern_strength
        
        if total_weight == 0:
            return 0.0
            
        # Calculate average alignment
        avg_alignment = total_alignment / total_weight
        
        return avg_alignment
    
    def _entropy_coherence(self, field: Any) -> float:
        """Calculate coherence based on entropy reduction."""
        # This is a simplified approximation of entropy-based coherence
        # A full implementation would use proper information theory metrics
        
        # Get patterns and attractors
        patterns = self._sample_patterns(field)
        attractors = self._get_attractors(field)
        
        if not patterns:
            return 0.0
            
        # Calculate pattern organization
        organization = 0.0
        total_strength = sum(strength for _, strength in patterns)
        
        for pattern, pattern_strength in patterns:
            # Find most resonant attractor
            best_resonance = 0.0
            for attractor, _ in attractors:
                resonance = self.resonance_measurer.measure(pattern, attractor)
                if resonance > best_resonance:
                    best_resonance = resonance
            
            # More organized patterns contribute to lower entropy
            pattern_organization = best_resonance * (pattern_strength / total_strength)
            organization += pattern_organization
        
        # Convert to coherence score (higher organization = higher coherence)
        coherence = organization
        
        return coherence
    
    def _sample_patterns(self, field: Any) -> List[Tuple[str, float]]:
        """Sample patterns from the field based on sampling strategy."""
        # Extract patterns from field
        try:
            patterns = [(pattern, strength) for pattern, strength in field.state.items()]
        except AttributeError:
            # Handle case where field structure is different
            try:
                patterns = field.get_patterns()
            except (AttributeError, TypeError):
                logger.warning("Could not extract patterns from field, using empty list")
                return []
        
        if not patterns:
            return []
            
        # Apply sampling strategy
        if self.sampling == "full" or len(patterns) <= self.sample_size:
            return patterns
            
        if self.sampling == "random":
            import random
            return random.sample(patterns, min(self.sample_size, len(patterns)))
            
        if self.sampling == "strength_weighted":
            # Sort by strength and take top patterns
            sorted_patterns = sorted(patterns, key=lambda x: x[1], reverse=True)
            return sorted_patterns[:self.sample_size]
            
        # Default to full sampling
        return patterns
    
    def _get_attractors(self, field: Any) -> List[Tuple[str, float]]:
        """Extract attractors from the field."""
        try:
            attractors = [(attractor['pattern'], attractor['strength']) 
                         for attractor in field.attractors.values()]
        except AttributeError:
            # Handle case where field structure is different
            try:
                attractors = field.get_attractors()
            except (AttributeError, TypeError):
                logger.warning("Could not extract attractors from field, using empty list")
                return []
        
        return attractors

# ------------------------------------------------------------------------------
# Stability Measurement
# ------------------------------------------------------------------------------

class StabilityMeasurer:
    """Measures stability of a neural field."""
    
    def __init__(self, attractor_weight: float = 0.6, organization_weight: float = 0.4):
        """
        Initialize the stability measurer.
        
        Args:
            attractor_weight: Weight for attractor strength in stability calculation
            organization_weight: Weight for pattern organization in stability calculation
        """
        self.attractor_weight = attractor_weight
        self.organization_weight = organization_weight
        self.coherence_measurer = CoherenceMeasurer()
    
    def measure(self, field: Any) -> float:
        """
        Measure stability of a field.
        
        Args:
            field: Neural field to measure
            
        Returns:
            Stability score (0.0 to 1.0)
        """
        # Get attractors
        attractors = self._get_attractors(field)
        
        if not attractors:
            return 0.0  # No attractors = no stability
            
        # Calculate average attractor strength
        avg_attractor_strength = sum(strength for _, strength in attractors) / len(attractors)
        
        # Calculate pattern organization (using coherence as a proxy)
        organization = self.coherence_measurer.measure(field)
        
        # Combine metrics
        stability = (avg_attractor_strength * self.attractor_weight) + (organization * self.organization_weight)
        
        return min(1.0, stability)  # Cap at 1.0
    
    def _get_attractors(self, field: Any) -> List[Tuple[str, float]]:
        """Extract attractors from the field."""
        try:
            attractors = [(attractor['pattern'], attractor['strength']) 
                         for attractor in field.attractors.values()]
        except AttributeError:
            # Handle case where field structure is different
            try:
                attractors = field.get_attractors()
            except (AttributeError, TypeError):
                logger.warning("Could not extract attractors from field, using empty list")
                return []
        
        return attractors

# ------------------------------------------------------------------------------
# Comprehensive Field Metrics
# ------------------------------------------------------------------------------

class FieldResonanceMeasurer:
    """
    Comprehensive tool for measuring neural field properties.
    Combines resonance, coherence, stability, and other metrics.
    """
    
    def __init__(self, config_path: Optional[str] = None):
        """
        Initialize the field resonance measurer.
        
        Args:
            config_path: Path to configuration file (YAML)
        """
        self.config = self._load_config(config_path)
        
        # Initialize component measurers
        self.resonance_measurer = ResonanceMeasurer(
            method=self.config.get('resonance', {}).get('method', 'cosine'),
            threshold=self.config.get('resonance', {}).get('threshold', 0.2),
            amplification=self.config.get('resonance', {}).get('amplification', 1.2)
        )
        
        self.coherence_measurer = CoherenceMeasurer(
            method=self.config.get('coherence', {}).get('method', 'attractor_alignment'),
            sampling=self.config.get('coherence', {}).get('sampling', 'strength_weighted'),
            sample_size=self.config.get('coherence', {}).get('sample_size', 100)
        )
        
        self.stability_measurer = StabilityMeasurer(
            attractor_weight=self.config.get('stability', {}).get('attractor_weight', 0.6),
            organization_weight=self.config.get('stability', {}).get('organization_weight', 0.4)
        )
    
    def _load_config(self, config_path: Optional[str]) -> Dict[str, Any]:
        """Load configuration from file or use defaults."""
        if config_path:
            try:
                with open(config_path, 'r') as f:
                    return yaml.safe_load(f)
            except Exception as e:
                logger.warning(f"Failed to load config from {config_path}: {e}")
                logger.info("Using default configuration")
        
        # Default configuration
        return {
            'resonance': {
                'method': 'cosine',
                'threshold': 0.2,
                'amplification': 1.2
            },
            'coherence': {
                'method': 'attractor_alignment',
                'sampling': 'strength_weighted',
                'sample_size': 100
            },
            'stability': {
                'attractor_weight': 0.6,
                'organization_weight': 0.4
            }
        }
    
    def measure_resonance(self, pattern1: str, pattern2: str) -> float:
        """
        Measure resonance between two patterns.
        
        Args:
            pattern1: First pattern
            pattern2: Second pattern
            
        Returns:
            Resonance score (0.0 to 1.0)
        """
        return self.resonance_measurer.measure(pattern1, pattern2)
    
    def measure_coherence(self, field: Any) -> float:
        """
        Measure coherence of a field.
        
        Args:
            field: Neural field to measure
            
        Returns:
            Coherence score (0.0 to 1.0)
        """
        return self.coherence_measurer.measure(field)
    
    def measure_stability(self, field: Any) -> float:
        """
        Measure stability of a field.
        
        Args:
            field: Neural field to measure
            
        Returns:
            Stability score (0.0 to 1.0)
        """
        return self.stability_measurer.measure(field)
    
    def get_field_metrics(self, field: Any) -> Dict[str, float]:
        """
        Get comprehensive metrics for a field.
        
        Args:
            field: Neural field to measure
            
        Returns:
            Dictionary of metrics
        """
        # Basic metrics
        metrics = {
            'coherence': self.measure_coherence(field),
            'stability': self.measure_stability(field)
        }
        
        # Add attractor metrics
        attractors = self._get_attractors(field)
        if attractors:
            metrics['attractor_count'] = len(attractors)
            metrics['avg_attractor_strength'] = sum(strength for _, strength in attractors) / len(attractors)
            metrics['max_attractor_strength'] = max(strength for _, strength in attractors) if attractors else 0.0
        else:
            metrics['attractor_count'] = 0
            metrics['avg_attractor_strength'] = 0.0
            metrics['max_attractor_strength'] = 0.0
        
        # Add pattern metrics
        patterns = self._get_patterns(field)
        if patterns:
            metrics['pattern_count'] = len(patterns)
            metrics['avg_pattern_strength'] = sum(strength for _, strength in patterns) / len(patterns)
        else:
            metrics['pattern_count'] = 0
            metrics['avg_pattern_strength'] = 0.0
        
        # Calculate entropy (information disorder)
        entropy = self._calculate_entropy(field)
        metrics['entropy'] = entropy
        
        # Calculate information density
        if patterns:
            total_chars = sum(len(pattern) for pattern, _ in patterns)
            metrics['information_density'] = total_chars / max(1, len(patterns))
        else:
            metrics['information_density'] = 0.0
        
        return metrics
    
    def _get_attractors(self, field: Any) -> List[Tuple[str, float]]:
        """Extract attractors from the field."""
        try:
            attractors = [(attractor['pattern'], attractor['strength']) 
                         for attractor in field.attractors.values()]
        except AttributeError:
            # Handle case where field structure is different
            try:
                attractors = field.get_attractors()
            except (AttributeError, TypeError):
                logger.warning("Could not extract attractors from field, using empty list")
                return []
        
        return attractors
    
    def _get_patterns(self, field: Any) -> List[Tuple[str, float]]:
        """Extract patterns from the field."""
        try:
            patterns = [(pattern, strength) for pattern, strength in field.state.items()]
        except AttributeError:
            # Handle case where field structure is different
            try:
                patterns = field.get_patterns()
            except (AttributeError, TypeError):
                logger.warning("Could not extract patterns from field, using empty list")
                return []
        
        return patterns
    
    def _calculate_entropy(self, field: Any) -> float:
        """
        Calculate the entropy (disorder) of the field.
        Higher entropy = more disorder = less organization.
        
        Args:
            field: Neural field to measure
            
        Returns:
            Entropy score (0.0 to 1.0)
        """
        # Get patterns
        patterns = self._get_patterns(field)
        
        if not patterns:
            return 1.0  # Maximum entropy for empty field
            
        # Calculate total strength
        total_strength = sum(strength for _, strength in patterns)
        
        if total_strength == 0:
            return 1.0
            
        # Calculate probabilities
        probabilities = [strength / total_strength for _, strength in patterns]
        
        # Calculate Shannon entropy
        entropy = -sum(p * math.log2(p) for p in probabilities if p > 0)
        
        # Normalize to 0-1 range
        max_entropy = math.log2(len(patterns))
        if max_entropy == 0:
            normalized_entropy = 0.0
        else:
            normalized_entropy = entropy / max_entropy
        
        return normalized_entropy
    
    def visualize_field(self, field: Any, format: str = "ascii") -> str:
        """
        Generate a visualization of the field.
        
        Args:
            field: Neural field to visualize
            format: Visualization format ("ascii", "text", "json")
            
        Returns:
            Visualization string
        """
        if format == "json":
            return self._visualize_json(field)
        elif format == "text":
            return self._visualize_text(field)
        else:
            return self._visualize_ascii(field)
    
    def _visualize_ascii(self, field: Any) -> str:
        """Generate ASCII visualization of the field."""
        # Get field components
        attractors = self._get_attractors(field)
        patterns = self._get_patterns(field)
        metrics = self.get_field_metrics(field)
        
        # Sort by strength
        attractors = sorted(attractors, key=lambda x: x[1], reverse=True)
        patterns = sorted(patterns, key=lambda x: x[1], reverse=True)
        
        # Build visualization
        lines = []
        lines.append("=" * 80)
        lines.append("NEURAL FIELD VISUALIZATION")
        lines.append("=" * 80)
        
        # Add metrics
        lines.append("FIELD METRICS:")
        lines.append(f"Coherence:    {'*' * int(metrics['coherence'] * 20):<20} {metrics['coherence']:.2f}")
        lines.append(f"Stability:     {'*' * int(metrics['stability'] * 20):<20} {metrics['stability']:.2f}")
        lines.append(f"Entropy:       {'*' * int(metrics['entropy'] * 20):<20} {metrics['entropy']:.2f}")
        lines.append(f"Attractors:    {metrics['attractor_count']}")
        lines.append(f"Patterns:      {metrics['pattern_count']}")
        lines.append("-" * 80)
        
        # Add attractors
        lines.append("ATTRACTORS:")
        for i, (pattern, strength) in enumerate(attractors[:5]):  # Show top 5
            short_pattern = pattern[:50] + "..." if len(pattern) > 50 else pattern
            lines.append(f"A{i+1} ({strength:.2f}): {'#' * int(strength * 20):<20} {short_pattern}")
        lines.append("-" * 80)
        
        # Add active patterns
        lines.append("ACTIVE PATTERNS:")
        for i, (pattern, strength) in enumerate(patterns[:7]):  # Show top 7
            short_pattern = pattern[:40] + "..." if len(pattern) > 40 else pattern
            lines.append(f"P{i+1} ({strength:.2f}): {'*' * int(strength * 20):<20} {short_pattern}")
        lines.append("-" * 80)
        
        # Add resonance visualization
        if attractors and patterns:
            lines.append("RESONANCE MAP:")
            # Show resonance between top attractors and patterns
            for i, (pattern, p_strength) in enumerate(patterns[:3]):  # Top 3 patterns
                for j, (attractor, a_strength) in enumerate(attractors[:3]):  # Top 3 attractors
                    resonance = self.resonance_measurer.measure(pattern, attractor)
                    if resonance > 0.2:  # Only show significant resonance
                        lines.append(f"P{i+1} ↔ A{j+1}: {'-' * int(resonance * 20):<20} {resonance:.2f}")
            lines.append("-" * 80)
        
        return "\n".join(lines)
    
    def _visualize_text(self, field: Any) -> str:
        """Generate text visualization of the field."""
        # Get field components
        attractors = self._get_attractors(field)
        patterns = self._get_patterns(field)
        metrics = self.get_field_metrics(field)
        
        # Build visualization
        lines = []
        lines.append("NEURAL FIELD STATE")
        lines.append("")
        
        # Add metrics
        lines.append("Field Metrics:")
        lines.append(f"- Coherence: {metrics['coherence']:.2f}")
        lines.append(f"- Stability: {metrics['stability']:.2f}")
        lines.append(f"- Entropy: {metrics['entropy']:.2f}")
        lines.append(f"- Attractor count: {metrics['attractor_count']}")
        lines.append(f"- Pattern count: {metrics['pattern_count']}")
        lines.append("")
        
        # Add attractors
        lines.append("Key Attractors:")
        for i, (pattern, strength) in enumerate(sorted(attractors, key=lambda x: x[1], reverse=True)[:3]):
            short_pattern = pattern[:100] + "..." if len(pattern) > 100 else pattern
            lines.append(f"- Attractor {i+1} (Strength: {strength:.2f}): {short_pattern}")
        lines.append("")
        
        # Add patterns
        lines.append("Active Patterns:")
        for i, (pattern, strength) in enumerate(sorted(patterns, key=lambda x: x[1], reverse=True)[:5]):
            short_pattern = pattern[:80] + "..." if len(pattern) > 80 else pattern
            lines.append(f"- Pattern {i+1} (Strength: {strength:.2f}): {short_pattern}")
        
        return "\n".join(lines)
    
    def _visualize_json(self, field: Any) -> str:
        """Generate JSON visualization of the field."""
        # Get field components
        attractors = self._get_attractors(field)
        patterns = self._get_patterns(field)
        metrics = self.get_field_metrics(field)
        
        # Prepare data structure
        data = {
            "metrics": metrics,
            "attractors": [
                {
                    "id": f"A{i+1}",
                    "pattern": pattern[:100] + "..." if len(pattern) > 100 else pattern,
                    "strength": strength
                }
                for i, (pattern, strength) in enumerate(sorted(attractors, key=lambda x: x[1], reverse=True)[:5])
            ],
            "patterns": [
                {
                    "id": f"P{i+1}",
                    "pattern": pattern[:80] + "..." if len(pattern) > 80 else pattern,
                    "strength": strength
                }
                for i, (pattern, strength) in enumerate(sorted(patterns, key=lambda x: x[1], reverse=True)[:7])
            ],
            "resonance": []
        }
        
        # Add resonance data
        if attractors and patterns:
            top_attractors = sorted(attractors, key=lambda x: x[1], reverse=True)[:3]
            top_patterns = sorted(patterns, key=lambda x: x[1], reverse=True)[:3]
            
            for i, (pattern, _) in enumerate(top_patterns):
                for j, (attractor, _) in enumerate(top_attractors):
                    resonance = self.resonance_measurer.measure(pattern, attractor)
                    if resonance > 0.2:  # Only include significant resonance
                        data["resonance"].append({
                            "source": f"P{i+1}",
                            "target": f"A{j+1}",
                            "strength": resonance
                        })
        
        # Convert to JSON
        return json.dumps(data, indent=2)

# ------------------------------------------------------------------------------
# Field Analysis Tools
# ------------------------------------------------------------------------------

class FieldAnalyzer:
    """Tools for analyzing neural fields and providing insights."""
    
    def __init__(self, measurer: Optional[FieldResonanceMeasurer] = None):
        """
        Initialize the field analyzer.
        
        Args:
            measurer: FieldResonanceMeasurer instance or None to create a new one
        """
        self.measurer = measurer or FieldResonanceMeasurer()
    
    def analyze_field(self, field: Any) -> Dict[str, Any]:
        """
        Perform comprehensive analysis of a field.
        
        Args:
            field: Neural field to analyze
            
        Returns:
            Analysis results
        """
        # Get basic metrics
        metrics = self.measurer.get_field_metrics(field)
        
        # Get field components
        attractors = self._get_attractors(field)
        patterns = self._get_patterns(field)
        
        # Analyze attractor structure
        attractor_analysis = self._analyze_attractors(attractors)
        
        # Analyze pattern organization
        pattern_analysis = self._analyze_patterns(patterns, attractors)
        
        # Analyze field evolution potential
        evolution_analysis = self._analyze_evolution_potential(field, metrics)
        
        # Compile analysis
        analysis = {
            "metrics": metrics,
            "attractor_analysis": attractor_analysis,
            "pattern_analysis": pattern_analysis,
            "evolution_analysis": evolution_analysis,
            "recommendations": self._generate_recommendations(metrics, attractor_analysis, pattern_analysis)
        }
        
        return analysis
    
    def _get_attractors(self, field: Any) -> List[Tuple[str, float]]:
        """Extract attractors from the field."""
        try:
            attractors = [(attractor['pattern'], attractor['strength']) 
                         for attractor in field.attractors.values()]
        except AttributeError:
            # Handle case where field structure is different
            try:
                attractors = field.get_attractors()
            except (AttributeError, TypeError):
                logger.warning("Could not extract attractors from field, using empty list")
                return []
        
        return attractors
    
    def _get_patterns(self, field: Any) -> List[Tuple[str, float]]:
        """Extract patterns from the field."""
        try:
            patterns = [(pattern, strength) for pattern, strength in field.state.items()]
        except AttributeError:
            # Handle case where field structure is different
            try:
                patterns = field.get_patterns()
            except (AttributeError, TypeError):
                logger.warning("Could not extract patterns from field, using empty list")
                return []
        
        return patterns
    
    def _analyze_attractors(self, attractors: List[Tuple[str, float]]) -> Dict[str, Any]:
        """
        Analyze attractor structure.
        
        Args:
            attractors: List of (pattern, strength) tuples
            
        Returns:
            Attractor analysis
        """
        if not attractors:
            return {
                "count": 0,
                "strength_distribution": "none",
                "diversity": 0.0,
                "dominant_theme": None
            }
        
        # Count attractors
        count = len(attractors)
        
        # Analyze strength distribution
        strengths = [strength for _, strength in attractors]
        max_strength = max(strengths)
        min_strength = min(strengths)
        avg_strength = sum(strengths) / count
        strength_range = max_strength - min_strength
        
        if strength_range < 0.2:
            strength_distribution = "uniform"
        elif max_strength > 0.8 and avg_strength < 0.5:
            strength_distribution = "dominant"
        else:
            strength_distribution = "balanced"
        
        # Analyze diversity
        # A simple approximation: check pairwise similarity
        total_similarity = 0.0
        pair_count = 0
        
        for i, (pattern1, _) in enumerate(attractors):
            for j, (pattern2, _) in enumerate(attractors):
                if i < j:  # Only compare each pair once
                    similarity = self.measurer.measure_resonance(pattern1, pattern2)
                    total_similarity += similarity
                    pair_count += 1
        
        diversity = 1.0 - (total_similarity / max(1, pair_count))
        
        # Identify dominant theme (simplified)
        strongest_attractor = max(attractors, key=lambda x: x[1])
        dominant_theme = strongest_attractor[0][:50] + "..." if len(strongest_attractor[0]) > 50 else strongest_attractor[0]
        
        return {
            "count": count,
            "strength_distribution": strength_distribution,
            "diversity": diversity,
            "dominant_theme": dominant_theme,
            "max_strength": max_strength,
            "min_strength": min_strength,
            "avg_strength": avg_strength
        }
    
    def _analyze_patterns(self, patterns: List[Tuple[str, float]], 
                         attractors: List[Tuple[str, float]]) -> Dict[str, Any]:
        """
        Analyze pattern organization.
        
        Args:
            patterns: List of (pattern, strength) tuples
            attractors: List of (pattern, strength) tuples
            
        Returns:
            Pattern analysis
        """
        if not patterns:
            return {
                "count": 0,
                "organization": "none",
                "attractor_alignment": 0.0,
                "fragmentation": 0.0
            }
        
        # Count patterns
        count = len(patterns)
        
        # Analyze pattern strength distribution
        strengths = [strength for _, strength in patterns]
        max_strength = max(strengths) if strengths else 0.0
        min_strength = min(strengths) if strengths else 0.0
        avg_strength = sum(strengths) / count if count > 0 else 0.0
        
        # Calculate attractor alignment
        if attractors:
            total_alignment = 0.0
            for pattern, pattern_strength in patterns:
                best_alignment = 0.0
                for attractor, _ in attractors:
                    alignment = self.measurer.measure_resonance(pattern, attractor)
                    if alignment > best_alignment:
                        best_alignment = alignment
                
                total_alignment += best_alignment * pattern_strength
            
            attractor_alignment = total_alignment / sum(strengths) if sum(strengths) > 0 else 0.0
        else:
            attractor_alignment = 0.0
        
        # Analyze fragmentation
        # Check how many disconnected pattern clusters exist
        if count > 1:
            # Simple approximation: count patterns with low similarity to any other
            isolated_patterns = 0
            for i, (pattern1, _) in enumerate(patterns):
                max_similarity = 0.0
                for j, (pattern2, _) in enumerate(patterns):
                    if i != j:
                        similarity = self.measurer.measure_resonance(pattern1, pattern2)
                        if similarity > max_similarity:
                            max_similarity = similarity
                
                if max_similarity < 0.3:  # Threshold for isolation
                    isolated_patterns += 1
            
            fragmentation = isolated_patterns / count
        else:
            fragmentation = 0.0
        
        # Determine organization type
        if attractor_alignment > 0.7:
            organization = "strongly_aligned"
        elif attractor_alignment > 0.4:
            organization = "moderately_aligned"
        elif fragmentation > 0.5:
            organization = "fragmented"
        else:
            organization = "loosely_connected"
        
        return {
            "count": count,
            "organization": organization,
            "attractor_alignment": attractor_alignment,
            "fragmentation": fragmentation,
            "max_strength": max_strength,
            "min_strength": min_strength,
            "avg_strength": avg_strength
        }
    
    def _analyze_evolution_potential(self, field: Any, metrics: Dict[str, float]) -> Dict[str, Any]:
        """
        Analyze field evolution potential.
        
        Args:
            field: Neural field to analyze
            metrics: Field metrics
            
        Returns:
            Evolution analysis
        """
        # Analyze stability vs. plasticity
        stability = metrics.get('stability', 0.0)
        entropy = metrics.get('entropy', 1.0)
        
        plasticity = 1.0 - stability
        
        # Determine evolution potential
        if stability > 0.8 and entropy < 0.3:
            # High stability, low entropy = rigid field
            evolution_potential = "limited"
            bottleneck = "field_rigidity"
        elif stability < 0.3 and entropy > 0.7:
            # Low stability, high entropy = chaotic field
            evolution_potential = "unstable"
            bottleneck = "field_instability"
        elif stability > 0.6 and entropy > 0.6:
            # High stability, high entropy = critical field
            evolution_potential = "optimal"
            bottleneck = None
        else:
            # Balanced field
            evolution_potential = "moderate"
            bottleneck = "needs_tuning"
        
        # Determine optimal operations
        if evolution_potential == "limited":
            recommended_operations = ["attenuate_attractors", "inject_novelty"]
        elif evolution_potential == "unstable":
            recommended_operations = ["strengthen_attractors", "prune_weak_patterns"]
        elif evolution_potential == "optimal":
            recommended_operations = ["maintain_balance", "selective_amplification"]
        else:
            recommended_operations = ["tune_parameters", "consolidate_patterns"]
        
        return {
            "evolution_potential": evolution_potential,
            "bottleneck": bottleneck,
            "stability": stability,
            "plasticity": plasticity,
            "recommended_operations": recommended_operations
        }
    
    def _generate_recommendations(self, metrics: Dict[str, float],
                                attractor_analysis: Dict[str, Any],
                                pattern_analysis: Dict[str, Any]) -> List[str]:
        """
        Generate recommendations for field improvement.
        
        Args:
            metrics: Field metrics
            attractor_analysis: Attractor analysis
            pattern_analysis: Pattern analysis
            
        Returns:
            List of recommendations
        """
        recommendations = []
        
        # Check attractor structure
        if attractor_analysis["count"] == 0:
            recommendations.append("Create initial attractors to provide field structure")
        elif attractor_analysis["count"] < 3:
            recommendations.append("Add more attractors to create a richer field structure")
        elif attractor_analysis["diversity"] < 0.3:
            recommendations.append("Increase attractor diversity to cover broader semantic space")
        
        if attractor_analysis.get("strength_distribution") == "dominant" and attractor_analysis.get("count") > 1:
            recommendations.append("Balance attractor strengths to avoid over-dominance")
        
        # Check pattern organization
        if pattern_analysis["organization"] == "fragmented":
            recommendations.append("Reduce fragmentation by strengthening relationships between patterns")
        
        if pattern_analysis["attractor_alignment"] < 0.3 and attractor_analysis["count"] > 0:
            recommendations.append("Improve alignment between patterns and attractors")
        
        # Check field metrics
        if metrics.get("coherence", 0.0) < 0.4:
            recommendations.append("Increase field coherence through pattern consolidation")
        
        if metrics.get("stability", 0.0) < 0.3:
            recommendations.append("Improve field stability by strengthening attractors")
        elif metrics.get("stability", 0.0) > 0.9:
            recommendations.append("Introduce controlled instability to enable field evolution")
        
        if metrics.get("entropy", 0.0) > 0.8:
            recommendations.append("Reduce entropy through pattern organization")
        elif metrics.get("entropy", 0.0) < 0.2:
            recommendations.append("Increase entropy to enable more diverse field states")
        
        # Ensure we have at least one recommendation
        if not recommendations:
            if metrics.get("coherence", 0.0) > 0.7 and metrics.get("stability", 0.0) > 0.7:
                recommendations.append("Maintain current field state with periodic reinforcement")
            else:
                recommendations.append("Tune field parameters based on application requirements")
        
        return recommendations

# ------------------------------------------------------------------------------
# Usage Examples
# ------------------------------------------------------------------------------

def measure_field_resonance_example():
    """Example usage of field resonance measurement."""
    # Create a simple mock field for demonstration
    class MockField:
        def __init__(self):
            self.state = {
                "Neural fields treat context as a continuous medium.": 0.9,
                "Information persists through resonance rather than explicit storage.": 0.8,
                "Patterns that align with existing field structures decay more slowly.": 0.7,
                "Field boundaries determine how information flows in and out.": 0.6,
                "New inputs interact with the entire field, not just recent tokens.": 0.5
            }
            self.attractors = {
                "attractor1": {
                    "pattern": "Neural fields represent context as a continuous semantic landscape.",
                    "strength": 0.9
                },
                "attractor2": {
                    "pattern": "Resonance is a key mechanism for information persistence.",
                    "strength": 0.8
                }
            }
    
    # Create a field
    field = MockField()
    
    # Create a measurer
    measurer = FieldResonanceMeasurer()
    
    # Measure resonance between two patterns
    pattern1 = "Neural fields enable persistent context."
    pattern2 = "Information persists in neural fields through resonance."
    resonance = measurer.measure_resonance(pattern1, pattern2)
    print(f"Resonance between patterns: {resonance:.2f}")
    
    # Measure field coherence
    coherence = measurer.measure_coherence(field)
    print(f"Field coherence: {coherence:.2f}")
    
    # Measure field stability
    stability = measurer.measure_stability(field)
    print(f"Field stability: {stability:.2f}")
    
    # Get comprehensive metrics
    metrics = measurer.get_field_metrics(field)
    print("Field metrics:")
    for key, value in metrics.items():
        print(f"- {key}: {value:.2f}")
    
    # Visualize the field
    visualization = measurer.visualize_field(field, format="ascii")
    print("\nField visualization:")
    print(visualization)
    
    # Analyze the field
    analyzer = FieldAnalyzer(measurer)
    analysis = analyzer.analyze_field(field)
    
    print("\nField analysis:")
    print(f"Evolution potential: {analysis['evolution_analysis']['evolution_potential']}")
    print("Recommendations:")
    for recommendation in analysis['recommendations']:
        print(f"- {recommendation}")

if __name__ == "__main__":
    # Example usage
    measure_field_resonance_example()
```
